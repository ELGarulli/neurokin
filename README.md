[![Documentation Status](https://readthedocs.org/projects/neurokin/badge/?version=latest)](https://neurokin.readthedocs.io/en/latest/?badge=latest)
![Tests](https://github.com/ELGarulli/neurokin/actions/workflows/test.yml/badge.svg)
[![GitHub Stars](https://img.shields.io/github/stars/ELGarulli/neurokin?style=social)](https://github.com/ELGarulli/neurokin/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/ELGarulli/neurokin?style=social)](https://github.com/ELGarulli/neurokin/network/members)
[![Downloads](https://static.pepy.tech/badge/neurokin)](https://pepy.tech/project/neurokin)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

# neurokin

neurokin aims to simplify the import and processing of neural and kinematic data. On top of basic preprocessing functions, it also provides more complex pipelines for multimodal data analysis. 
neurokin supports TDT and open_ephys formats natively for neural and .c3d files and DeepLabCut datasets for kinematics data but can be expanded easily. Please get in touch if you have another type of data.

To install use: 

    pip install neurokin

See the [documentation](https://neurokin.readthedocs.io/en/latest/) for example analysis


<p align="center">
  <img src="https://github.com/user-attachments/assets/0ac3c436-f3f8-4c6a-a689-e359dbbbe4cb" />
</p>
